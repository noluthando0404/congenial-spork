{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-09T11:58:28.297955Z","iopub.execute_input":"2022-12-09T11:58:28.298384Z","iopub.status.idle":"2022-12-09T11:58:28.309958Z","shell.execute_reply.started":"2022-12-09T11:58:28.298350Z","shell.execute_reply":"2022-12-09T11:58:28.308542Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"/kaggle/input/south-african-language-identification-hack-2022/sample_submission.csv\n/kaggle/input/south-african-language-identification-hack-2022/test_set.csv\n/kaggle/input/south-african-language-identification-hack-2022/train_set.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This is a baseline model created on kaggle, \n# MEANT TO BE IMPROVED UPON!!!","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import collections # used for dictionaries and counters\nfrom itertools import permutations # used to find permutations","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:58:28.561125Z","iopub.execute_input":"2022-12-09T11:58:28.561612Z","iopub.status.idle":"2022-12-09T11:58:28.568155Z","shell.execute_reply.started":"2022-12-09T11:58:28.561577Z","shell.execute_reply":"2022-12-09T11:58:28.566302Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2022/train_set.csv')\ntest = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2022/test_set.csv')\nss = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:58:28.729553Z","iopub.execute_input":"2022-12-09T11:58:28.729999Z","iopub.status.idle":"2022-12-09T11:58:28.900936Z","shell.execute_reply.started":"2022-12-09T11:58:28.729961Z","shell.execute_reply":"2022-12-09T11:58:28.899762Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:58:28.923669Z","iopub.execute_input":"2022-12-09T11:58:28.924133Z","iopub.status.idle":"2022-12-09T11:58:28.937264Z","shell.execute_reply.started":"2022-12-09T11:58:28.924089Z","shell.execute_reply":"2022-12-09T11:58:28.935876Z"},"trusted":true},"execution_count":144,"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"  lang_id                                               text\n0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n2     eng  the province of kwazulu-natal department of tr...\n3     nso  o netefatša gore o ba file dilo ka moka tše le...\n4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lang_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xho</td>\n      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xho</td>\n      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eng</td>\n      <td>the province of kwazulu-natal department of tr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>nso</td>\n      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ven</td>\n      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:58:29.661695Z","iopub.execute_input":"2022-12-09T11:58:29.662221Z","iopub.status.idle":"2022-12-09T11:58:29.676757Z","shell.execute_reply.started":"2022-12-09T11:58:29.662185Z","shell.execute_reply":"2022-12-09T11:58:29.674741Z"},"trusted":true},"execution_count":145,"outputs":[{"execution_count":145,"output_type":"execute_result","data":{"text/plain":"   index                                               text\n0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n3      4  Kube inja nelikati betingevakala kutsi titsini...\n4      5                      Winste op buitelandse valuta.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Winste op buitelandse valuta.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"- converting the values from object to strings","metadata":{}},{"cell_type":"code","source":"def trans_data(dataset):\n    # Define a list of commonly found punctuations\n    punc = ('!', \",\" ,\"\\'\" ,\";\" ,\"\\\"\", \".\", \"-\" ,\"?\")\n    vowels=['a','e','i','o','u']\n    # Define a list of double consecutive vowels which are typically found in Dutch and Afrikaans languages\n    same_consecutive_vowels = ['aa','ee', 'ii', 'oo', 'uu'] \n    consecutive_vowels = [''.join(p) for p in permutations(vowels,2)]\n    dutch_combos = ['ij']\n    data = dataset.copy()\n    data['text'] = data['text'].astype(str)\n    # Create a pre-defined set of features based on the \"text\" column in order to allow us to characterize the string\n    data['word_count'] = data['text'].apply(lambda x : len(x.split()))\n    data['character_count'] = data['text'].apply(lambda x : len(x.replace(\" \",\"\")))\n    data['word_density'] = data['word_count'] / (data['character_count'] + 1)\n    data['punc_count'] = data['text'].apply(lambda x : len([a for a in x if a in punc]))\n    data['v_char_count'] = data['text'].apply(lambda x : len([a for a in x if a.casefold() == 'v']))\n    data['w_char_count'] = data['text'].apply(lambda x : len([a for a in x if a.casefold() == 'w']))\n    data['ij_char_count'] = data['text'].apply(lambda x : sum([any(d_c in a for d_c in dutch_combos) for a in x.split()]))\n    data['num_double_consec_vowels'] = data['text'].apply(lambda x : sum([any(c_v in a for c_v in same_consecutive_vowels) for a in x.split()]))\n    data['num_consec_vowels'] = data['text'].apply(lambda x : sum([any(c_v in a for c_v in consecutive_vowels) for a in x.split()]))\n    data['num_vowels'] = data['text'].apply(lambda x : sum([any(v in a for v in vowels) for a in x.split()]))\n    data['vowel_density'] = data['num_vowels']/data['word_count']\n    data['capitals'] = data['text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n    data['caps_vs_length'] = data.apply(lambda row: float(row['capitals'])/float(row['character_count']),axis=1)\n    data['num_exclamation_marks'] =data['text'].apply(lambda x: x.count('!'))\n    data['num_question_marks'] = data['text'].apply(lambda x: x.count('?'))\n    data['num_punctuation'] = data['text'].apply(lambda x: sum(x.count(w) for w in punc))\n    data['num_unique_words'] = data['text'].apply(lambda x: len(set(w for w in x.split())))\n    data['num_repeated_words'] = data['text'].apply(lambda x: len([w for w in collections.Counter(x.split()).values() if w > 1]))\n    data['words_vs_unique'] = data['num_unique_words'] / data['word_count']\n    data['encode_ascii'] = np.nan\n    for i in range(len(data)):\n        try:\n            data['text'].iloc[i].encode(encoding='utf-8').decode('ascii')\n        except UnicodeDecodeError:\n            data['encode_ascii'].iloc[i] = 0\n        else:\n            data['encode_ascii'].iloc[i] = 1\n            \n    return data","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:58:32.880697Z","iopub.execute_input":"2022-12-09T11:58:32.881182Z","iopub.status.idle":"2022-12-09T11:58:33.336000Z","shell.execute_reply.started":"2022-12-09T11:58:32.881145Z","shell.execute_reply":"2022-12-09T11:58:33.334334Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = trans_data(train)\ntest = trans_data(test)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:58:33.585642Z","iopub.execute_input":"2022-12-09T11:58:33.586158Z","iopub.status.idle":"2022-12-09T11:59:03.151675Z","shell.execute_reply.started":"2022-12-09T11:58:33.586122Z","shell.execute_reply":"2022-12-09T11:59:03.150250Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_block(indexer, value, name)\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 29.4 s, sys: 11.4 ms, total: 29.5 s\nWall time: 29.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:03.154013Z","iopub.execute_input":"2022-12-09T11:59:03.154423Z","iopub.status.idle":"2022-12-09T11:59:03.186578Z","shell.execute_reply.started":"2022-12-09T11:59:03.154388Z","shell.execute_reply":"2022-12-09T11:59:03.184527Z"},"trusted":true},"execution_count":148,"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"  lang_id                                               text  word_count  \\\n0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...          24   \n1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...          31   \n2     eng  the province of kwazulu-natal department of tr...          37   \n3     nso  o netefatša gore o ba file dilo ka moka tše le...          40   \n4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...          43   \n\n   character_count  word_density  punc_count  v_char_count  w_char_count  \\\n0              197      0.121212           1             0             6   \n1              222      0.139013           2             1             4   \n2              228      0.161572           1             3             4   \n3              178      0.223464           0             0             1   \n4              197      0.217172           0             1             3   \n\n   ij_char_count  num_double_consec_vowels  ...  vowel_density  capitals  \\\n0              0                         0  ...          1.000         0   \n1              0                         1  ...          1.000         0   \n2              0                         0  ...          1.000         0   \n3              0                         0  ...          0.975         0   \n4              0                         1  ...          1.000         0   \n\n   caps_vs_length  num_exclamation_marks  num_question_marks  num_punctuation  \\\n0             0.0                      0                   0                1   \n1             0.0                      0                   0                2   \n2             0.0                      0                   0                1   \n3             0.0                      0                   0                0   \n4             0.0                      0                   0                0   \n\n   num_unique_words  num_repeated_words  words_vs_unique  encode_ascii  \n0                23                   1         0.958333           1.0  \n1                30                   1         0.967742           1.0  \n2                27                   5         0.729730           1.0  \n3                31                   5         0.775000           0.0  \n4                24                   8         0.558140           1.0  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lang_id</th>\n      <th>text</th>\n      <th>word_count</th>\n      <th>character_count</th>\n      <th>word_density</th>\n      <th>punc_count</th>\n      <th>v_char_count</th>\n      <th>w_char_count</th>\n      <th>ij_char_count</th>\n      <th>num_double_consec_vowels</th>\n      <th>...</th>\n      <th>vowel_density</th>\n      <th>capitals</th>\n      <th>caps_vs_length</th>\n      <th>num_exclamation_marks</th>\n      <th>num_question_marks</th>\n      <th>num_punctuation</th>\n      <th>num_unique_words</th>\n      <th>num_repeated_words</th>\n      <th>words_vs_unique</th>\n      <th>encode_ascii</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xho</td>\n      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n      <td>24</td>\n      <td>197</td>\n      <td>0.121212</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>23</td>\n      <td>1</td>\n      <td>0.958333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xho</td>\n      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n      <td>31</td>\n      <td>222</td>\n      <td>0.139013</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.967742</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eng</td>\n      <td>the province of kwazulu-natal department of tr...</td>\n      <td>37</td>\n      <td>228</td>\n      <td>0.161572</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>27</td>\n      <td>5</td>\n      <td>0.729730</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>nso</td>\n      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n      <td>40</td>\n      <td>178</td>\n      <td>0.223464</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.975</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>5</td>\n      <td>0.775000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ven</td>\n      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n      <td>43</td>\n      <td>197</td>\n      <td>0.217172</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>8</td>\n      <td>0.558140</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ntrain['lang_id'] = le.fit_transform(train[\"lang_id\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:03.188540Z","iopub.execute_input":"2022-12-09T11:59:03.188943Z","iopub.status.idle":"2022-12-09T11:59:03.207623Z","shell.execute_reply.started":"2022-12-09T11:59:03.188909Z","shell.execute_reply":"2022-12-09T11:59:03.205387Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"target = train.pop('lang_id')\ntext = train.pop('text')\n\ntest_text = test.pop('text')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:03.231890Z","iopub.execute_input":"2022-12-09T11:59:03.232451Z","iopub.status.idle":"2022-12-09T11:59:03.245762Z","shell.execute_reply.started":"2022-12-09T11:59:03.232405Z","shell.execute_reply":"2022-12-09T11:59:03.244435Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"test_index = test.pop('index')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T12:00:31.475498Z","iopub.execute_input":"2022-12-09T12:00:31.475990Z","iopub.status.idle":"2022-12-09T12:00:31.483382Z","shell.execute_reply.started":"2022-12-09T12:00:31.475952Z","shell.execute_reply":"2022-12-09T12:00:31.481181Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#split dataset into features and target variable\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.2) # 80% train and 20% test","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:31.141295Z","iopub.execute_input":"2022-12-09T11:59:31.141723Z","iopub.status.idle":"2022-12-09T11:59:31.166579Z","shell.execute_reply.started":"2022-12-09T11:59:31.141691Z","shell.execute_reply":"2022-12-09T11:59:31.165059Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nimport lightgbm","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:32.151229Z","iopub.execute_input":"2022-12-09T11:59:32.152213Z","iopub.status.idle":"2022-12-09T11:59:32.159240Z","shell.execute_reply.started":"2022-12-09T11:59:32.152160Z","shell.execute_reply":"2022-12-09T11:59:32.157207Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"dt_clf = DecisionTreeClassifier() # Create Decision Tree classifer object\ndt_clf = dt_clf.fit(X_train,y_train) # Fit/Train Decision Tree Classifer on training set\n\n# Save model to file in the current working directory so that it can be imported and used.\n# I use the pickle library to save the parameters of the trained model\n# pkl_file = \"decision_tree_model.pkl\"\n# with open(pkl_file, 'wb') as file:\n#     pickle.dump(dt_clf, file)\n\n# # Load previously trained model from pickle file\n# with open(pkl_file, 'rb') as file:\n#     dt_clf = pickle.load(file)\n\n# dt_clf # parameters of the Decision Tree model are shown below and can be further optimized to improve model performance\n\ny_pred = dt_clf.predict(X_test) #Predict the response for test dataset","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:32.587976Z","iopub.execute_input":"2022-12-09T11:59:32.588410Z","iopub.status.idle":"2022-12-09T11:59:32.872811Z","shell.execute_reply.started":"2022-12-09T11:59:32.588378Z","shell.execute_reply":"2022-12-09T11:59:32.871548Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:33.326026Z","iopub.execute_input":"2022-12-09T11:59:33.326589Z","iopub.status.idle":"2022-12-09T11:59:33.334917Z","shell.execute_reply.started":"2022-12-09T11:59:33.326550Z","shell.execute_reply":"2022-12-09T11:59:33.332962Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy of the Decision Tree Model\naccuracy_score_dt = accuracy_score(y_test, y_pred)\naccuracy_score_dt","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:34.340702Z","iopub.execute_input":"2022-12-09T11:59:34.341510Z","iopub.status.idle":"2022-12-09T11:59:34.355850Z","shell.execute_reply.started":"2022-12-09T11:59:34.341439Z","shell.execute_reply":"2022-12-09T11:59:34.353409Z"},"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"0.6628787878787878"},"metadata":{}}]},{"cell_type":"code","source":"z = lightgbm.LGBMClassifier()\nz.fit(X_train,y_train)\naccuracy_score(z.predict(X_test) , y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:37.695124Z","iopub.execute_input":"2022-12-09T11:59:37.695629Z","iopub.status.idle":"2022-12-09T11:59:41.234338Z","shell.execute_reply.started":"2022-12-09T11:59:37.695595Z","shell.execute_reply":"2022-12-09T11:59:41.232941Z"},"trusted":true},"execution_count":158,"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"0.708030303030303"},"metadata":{}}]},{"cell_type":"code","source":"rf_clf = RandomForestClassifier(n_estimators=100) # Create Random Forest classifer object\nrf_clf = rf_clf.fit(X_train,y_train) # Fit/Train Random Forest Classifer on training set\n\n#Predict the response for test dataset\naccuracy_score(y_test , rf_clf.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T11:59:44.206518Z","iopub.execute_input":"2022-12-09T11:59:44.206961Z","iopub.status.idle":"2022-12-09T11:59:49.646281Z","shell.execute_reply.started":"2022-12-09T11:59:44.206927Z","shell.execute_reply":"2022-12-09T11:59:49.644990Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"0.7222727272727273"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\ntrans_train = sc.fit_transform(train)\ntrans_test = sc.fit_transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T12:00:46.423144Z","iopub.execute_input":"2022-12-09T12:00:46.423870Z","iopub.status.idle":"2022-12-09T12:00:46.459231Z","shell.execute_reply.started":"2022-12-09T12:00:46.423830Z","shell.execute_reply":"2022-12-09T12:00:46.457324Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"rf_clf.predict(trans_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T12:00:49.026564Z","iopub.execute_input":"2022-12-09T12:00:49.027030Z","iopub.status.idle":"2022-12-09T12:00:49.141667Z","shell.execute_reply.started":"2022-12-09T12:00:49.026995Z","shell.execute_reply":"2022-12-09T12:00:49.139087Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n","output_type":"stream"},{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"array([3, 5, 3, ..., 3, 3, 5])"},"metadata":{}}]},{"cell_type":"code","source":"preds = np.vstack(le.inverse_transform(rf_clf.predict(test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T12:01:16.151314Z","iopub.execute_input":"2022-12-09T12:01:16.152219Z","iopub.status.idle":"2022-12-09T12:01:16.346883Z","shell.execute_reply.started":"2022-12-09T12:01:16.152174Z","shell.execute_reply":"2022-12-09T12:01:16.345522Z"},"trusted":true},"execution_count":169,"outputs":[{"execution_count":169,"output_type":"execute_result","data":{"text/plain":"array([['sot'],\n       ['ssw'],\n       ['tso'],\n       ...,\n       ['tsn'],\n       ['tsn'],\n       ['zul']], dtype='<U3')"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(zed).to_csv('preds.csv' , index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T12:04:50.833730Z","iopub.execute_input":"2022-12-09T12:04:50.834159Z","iopub.status.idle":"2022-12-09T12:04:50.853299Z","shell.execute_reply.started":"2022-12-09T12:04:50.834126Z","shell.execute_reply":"2022-12-09T12:04:50.851968Z"},"trusted":true},"execution_count":177,"outputs":[{"execution_count":177,"output_type":"execute_result","data":{"text/plain":"      Index Target\n0         1    sot\n1         2    ssw\n2         3    tso\n3         4    zul\n4         5    zul\n...     ...    ...\n5677   5678    sot\n5678   5679    nso\n5679   5680    tsn\n5680   5681    tsn\n5681   5682    zul\n\n[5682 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Index</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sot</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>ssw</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>tso</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>zul</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>zul</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5677</th>\n      <td>5678</td>\n      <td>sot</td>\n    </tr>\n    <tr>\n      <th>5678</th>\n      <td>5679</td>\n      <td>nso</td>\n    </tr>\n    <tr>\n      <th>5679</th>\n      <td>5680</td>\n      <td>tsn</td>\n    </tr>\n    <tr>\n      <th>5680</th>\n      <td>5681</td>\n      <td>tsn</td>\n    </tr>\n    <tr>\n      <th>5681</th>\n      <td>5682</td>\n      <td>zul</td>\n    </tr>\n  </tbody>\n</table>\n<p>5682 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ss","metadata":{"execution":{"iopub.status.busy":"2022-12-09T12:20:53.505060Z","iopub.execute_input":"2022-12-09T12:20:53.505577Z","iopub.status.idle":"2022-12-09T12:20:53.518265Z","shell.execute_reply.started":"2022-12-09T12:20:53.505538Z","shell.execute_reply":"2022-12-09T12:20:53.516889Z"},"trusted":true},"execution_count":178,"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"   index lang_id\n0      1     tsn\n1      2     nbl","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>lang_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>tsn</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>nbl</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}